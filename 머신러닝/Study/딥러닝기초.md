# 딥러닝 기초(이론정리)



### 회귀

> 지도학습의 경우 데이터를 통해 학습하는 레이블이 어떤성질을 띄냐에 따라
> 회귀(Regression)와 분류(Classification)로 구분됨



#### 선형회귀(Linear regression) 

> 선형 회귀란 **독립 변수 x를 사용해 종속 변수 y의 움직임을 예측하고 설명**하는 작업
> (예측에 사용 cost function 으로 MSE를 사용)



**[종류]**

1. 최소제곱법

   최소 제곱법이란 회귀 분석에서 사용되는 표준 방식으로. 실험이나 관찰을 통해 얻은 데이터를 분석하여 미지의 상수를 구할 때 사용되는 공식

   

2. 경사하강법

   해당 함수의 최소값 위치를 찾기 위해 **비용(손실)함수**의 **기울기** 반대 방향으로 정의한 step size를 가지고 조금씩 움직여 가면서 최적의 파라미터를 찾으려는 방법

   - Momentum

     : 이전의 기울기에 영향을 받아, 계속 이동하는 방향으로 이동함

   - AdaGrad

     : 변수별로 학습률이 다르게 하는 방법(학습이 더 오래 지속되면 학습이 안된다는 단점이 있어, RMSProp이 생김)

   - RMSProp

     : 합대신 지수 평균을 사용한다.
     (상대적 학습률의 차이는 유지하면 기울기의 누적크기가 무한으로 커지지 않아 학습을 오래 할 수 있다.)

   - Adam

     : Momentum + RMSProp

     

#### 로지스틱 회귀(Cross entropy error)

> 실생활에서 모든 원인과 결과는 직선 형태로 표현할 수 없음. 직선으로만 하면 정확도가 떨어지고 이부분을 보완하기 위해 나온 개념이 '로지스틱 회귀' (분류에 사용cost function으로  CEE를 사용)
>
> 직선이 아닌 시그모이드, 소프트맥스와 같은 곡선을 사용한다



**[종류]**

1. 시그모이드(Sigmoid) 함수

   바이너리 로지스틱 회귀에 주로 사용. 시그모이드 함수는 결과 값을 0,1로 반환한다. 때문에 두 가지로 분류할 때 유용하다.

   

2. 소프트맥스(Softmax) 함수

   softmax 함수 또한 시그모이드처럼 활성화 함수이고, 여러개를 분류하는데 특화되어 있다. 시그모이드를 여러개 사용하여 분류할 수도 있지만 그렇게 하면 정규화가 되어있지 않기 때문에 효율성이 떨어진다. 반면 softmax는 출력값들이 정규화가 되어있기 때문에 결과값들의 합은 1을 나타낸다. ex) A 0.2 / B 0.2 / C 0.6 -> C가 될 확률이 60%

   

3. 최대 우도 추정법

   시그모이드 함수를 최적화 할 수 있다. 어떤 확률변수에서 표집한 값들을 토대로 그 확률변수의 모수를 구하는 방법이다. 어떤 모수가 주어졌을 때, 원하는 값들이 나올 가능도를 최대로 만드는 모수를 선택하는 방법이다.



---



### 모델(Model)

> 데이터를 바라보는 시점과 가정

1. 간단한 모델
   1. 선형모델(선형회귀 Linear regression)
2. 복잡한 모델
   1. 결정트리(Decision Tree)
3. 구조가 있는 모델
   1. 순차모델(Sequence model) - RNN
   2. 그래프 모델(graphical model)



### 손실함수(loss function)

> 모델이 실제로 데이터를 바르게 표현했는지 혹은 얼마나 예측이 정확한지 수학적으로 표현하는것
>
> loss function, cost function, objective function 모두 같은 표현이다. 



1. 산술 손실함수 
   - Mean Squared Error(MSE)
   - 모델로 산술값을 예측할 때 데이터에 대한 예측값과 실제 관측값을 비교하는 함수
   - **주로 회귀(예측)문제에 사용된다**

2. 확률 손실함수
   - Cross entropy error(CEE)
   - 모델로 항목이나 값에 대한 확률을 예측하는 경우에 사용한다.
   - 매우 유연하기 때문에 회귀문제에 보현적으로 사용된다(분류)
   - 원-핫 인코딩 출력으로 결과를 쉽게 확인 할 수 있다.















브런치 참고자료

https://brunch.co.kr/@morningb/3